<!DOCTYPE html><html>
<head>
<title>Monte Carlo simulation</title>
<!--Generated on Sat Feb 10 12:35:05 2018 by LaTeXML (version 0.8.2) http://dlmf.nist.gov/LaTeXML/.-->

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="LaTeXML.css" type="text/css">
<link rel="stylesheet" href="ltx-article.css" type="text/css">
<link rel="stylesheet" href="https://cdn.rawgit.com/holtzermann17/3f71ceeb3b055e1ddc3b6c11fb1f074c/raw/2bb23e3b173ff96840797fc0c3bcb8c54085df8e/LaTeXML.css" type="text/css">
<link rel="stylesheet" href="https://cdn.rawgit.com/holtzermann17/4bda0365b30858ac2fb83623185fe3ec/raw/cedd84ed3e3ad597c5d293f443ecfe4803741c6b/ltx-article.css" type="text/css">
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Monte Carlo simulation</h1>

<div id="p1" class="ltx_para">
<br class="ltx_break">
<p class="ltx_p"><em class="ltx_emph ltx_font_italic">Monte Carlo simulation</em>
is the use of randomized numerical experiments
to evaluate mathematical expressions.</p>
</div>
<div id="p2" class="ltx_para">
<p class="ltx_p">In the typical problems addressed by Monte Carlo simulation,
the search space or sample space is countably or uncountably infinite.
In contrast to determistic algorithms that sweep a finite subset of points
in the search space in order to derive a solution
to the problem, Monte Carlo simulation randomizes the selection
of points in the hope that good representatives for the solution
of the problem are chosen.</p>
</div>
<section id="S0.SSx1" class="ltx_subsection">
<h2 class="ltx_title ltx_title_subsection">Monte Carlo integration</h2>

<div id="S0.SSx1.p1" class="ltx_para">
<p class="ltx_p">The term Monte Carlo simulation most often
refers to integration by randomized methods.
The problem is to evaluate the expectation or integral</p>
<table id="S0.Ex1" class="ltx_equation ltx_eqn_table">

<tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S0.Ex1.m1" class="ltx_Math" alttext="\mathbb{E}X=\int X\,d\mathbb{P}" display="block"><mrow><mrow><mi>ùîº</mi><mo>‚Å¢</mo><mi>X</mi></mrow><mo>=</mo><mrow><mo largeop="true" symmetric="true">‚à´</mo><mrow><mpadded width="+1.7pt"><mi>X</mi></mpadded><mo>‚Å¢</mo><mrow><mo>ùëë</mo><mi>‚Ñô</mi></mrow></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</table>
<p class="ltx_p">of a real-valued
random variable <math id="S0.SSx1.p1.m1" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math> on a probability space.
The expectation is approximated by taking the sample mean
of independent observations <math id="S0.SSx1.p1.m2" class="ltx_Math" alttext="\{X_{i}\}" display="inline"><mrow><mo stretchy="false">{</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">}</mo></mrow></math> with the same distribution
as <math id="S0.SSx1.p1.m3" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math>:</p>
<table id="S0.Ex2" class="ltx_equation ltx_eqn_table">

<tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S0.Ex2.m1" class="ltx_Math" alttext="\mathbb{E}X\approx\frac{1}{n}\sum_{i=1}^{n}X_{i}\,." display="block"><mrow><mrow><mrow><mi>ùîº</mi><mo>‚Å¢</mo><mi>X</mi></mrow><mo>‚âà</mo><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>‚Å¢</mo><mrow><munderover><mo largeop="true" movablelimits="false" symmetric="true">‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mpadded width="+1.7pt"><msub><mi>X</mi><mi>i</mi></msub></mpadded></mrow></mrow></mrow><mo>.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</table>
<p class="ltx_p">By the strong law of large numbers, the sample mean
converges almost surely, as <math id="S0.SSx1.p1.m4" class="ltx_Math" alttext="n\to\infty" display="inline"><mrow><mi>n</mi><mo>‚Üí</mo><mi mathvariant="normal">‚àû</mi></mrow></math>, to the true mean <math id="S0.SSx1.p1.m5" class="ltx_Math" alttext="\mathbb{E}X" display="inline"><mrow><mi>ùîº</mi><mo>‚Å¢</mo><mi>X</mi></mrow></math>.</p>
</div>
<div id="S0.SSx1.p2" class="ltx_para">
<p class="ltx_p">Typically the distribution of <math id="S0.SSx1.p2.m1" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math> is not known in closed form;
otherwise we would be able to use the standard numerical quadrature
techniques to compute the one-dimensional integral representing <math id="S0.SSx1.p2.m2" class="ltx_Math" alttext="\mathbb{E}X" display="inline"><mrow><mi>ùîº</mi><mo>‚Å¢</mo><mi>X</mi></mrow></math>,
and one-variable quadrature
in general tend to work better than the Monte Carlo method.</p>
</div>
<div id="S0.SSx1.p3" class="ltx_para">
<p class="ltx_p">Rather, the random variable <math id="S0.SSx1.p3.m1" class="ltx_Math" alttext="X=f(Y)" display="inline"><mrow><mi>X</mi><mo>=</mo><mrow><mi>f</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></math> is expressed as some function <math id="S0.SSx1.p3.m2" class="ltx_Math" alttext="f" display="inline"><mi>f</mi></math>
of another random variable <math id="S0.SSx1.p3.m3" class="ltx_Math" alttext="Y" display="inline"><mi>Y</mi></math>, and we know how to compute <math id="S0.SSx1.p3.m4" class="ltx_Math" alttext="f" display="inline"><mi>f</mi></math>
and randomized samples of <math id="S0.SSx1.p3.m5" class="ltx_Math" alttext="Y" display="inline"><mi>Y</mi></math>.
Then</p>
<table id="S0.Ex3" class="ltx_equation ltx_eqn_table">

<tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S0.Ex3.m1" class="ltx_Math" alttext="\mathbb{E}X=\mathbb{E}[f(Y)]\approx\frac{1}{n}\sum_{i=1}^{n}f(Y_{i})" display="block"><mrow><mrow><mi>ùîº</mi><mo>‚Å¢</mo><mi>X</mi></mrow><mo>=</mo><mrow><mi>ùîº</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">[</mo><mrow><mi>f</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">]</mo></mrow></mrow><mo>‚âà</mo><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>‚Å¢</mo><mrow><munderover><mo largeop="true" movablelimits="false" symmetric="true">‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mi>f</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</table>
<p class="ltx_p">for independent samples <math id="S0.SSx1.p3.m6" class="ltx_Math" alttext="\{Y_{i}\}" display="inline"><mrow><mo stretchy="false">{</mo><msub><mi>Y</mi><mi>i</mi></msub><mo stretchy="false">}</mo></mrow></math>
for the random variable <math id="S0.SSx1.p3.m7" class="ltx_Math" alttext="Y" display="inline"><mi>Y</mi></math>.</p>
</div>
<div id="S0.SSx1.p4" class="ltx_para">
<p class="ltx_p">The realizations <math id="S0.SSx1.p4.m1" class="ltx_Math" alttext="Y_{i}" display="inline"><msub><mi>Y</mi><mi>i</mi></msub></math>
may be obtained by generating random (or pseudo-random)
samples according to the known distribution for <math id="S0.SSx1.p4.m2" class="ltx_Math" alttext="Y" display="inline"><mi>Y</mi></math>.
Or, in some cases, they may be obtained from pre-tabulated
observations, e.g. based on past observations in the real world.</p>
</div>
</section>
<section id="S0.SSx2" class="ltx_subsection">
<h2 class="ltx_title ltx_title_subsection">Bounds on error</h2>

<div id="S0.SSx2.p1" class="ltx_para">
<p class="ltx_p">If <math id="S0.SSx2.p1.m1" class="ltx_Math" alttext="X_{1},X_{2},\ldots" display="inline"><mrow><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><msub><mi>X</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">‚Ä¶</mi></mrow></math> are identically and independently distributed,
with mean <math id="S0.SSx2.p1.m2" class="ltx_Math" alttext="m" display="inline"><mi>m</mi></math> and variance <math id="S0.SSx2.p1.m3" class="ltx_Math" alttext="v" display="inline"><mi>v</mi></math>,
then</p>
<table id="S0.Ex4" class="ltx_equation ltx_eqn_table">

<tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S0.Ex4.m1" class="ltx_Math" alttext="\frac{1}{\sqrt{n}}\sum_{i=1}^{n}\frac{X_{i}-m}{\sqrt{v}}" display="block"><mrow><mfrac><mn>1</mn><msqrt><mi>n</mi></msqrt></mfrac><mo>‚Å¢</mo><mrow><munderover><mo largeop="true" movablelimits="false" symmetric="true">‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mfrac><mrow><msub><mi>X</mi><mi>i</mi></msub><mo>-</mo><mi>m</mi></mrow><msqrt><mi>v</mi></msqrt></mfrac></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</table>
<p class="ltx_p">converges in distribution,
as <math id="S0.SSx2.p1.m4" class="ltx_Math" alttext="n\to\infty" display="inline"><mrow><mi>n</mi><mo>‚Üí</mo><mi mathvariant="normal">‚àû</mi></mrow></math>, to the standard normal distribution.
Then for any <math id="S0.SSx2.p1.m5" class="ltx_Math" alttext="\delta&gt;0" display="inline"><mrow><mi>Œ¥</mi><mo>&gt;</mo><mn>0</mn></mrow></math>, and for large <math id="S0.SSx2.p1.m6" class="ltx_Math" alttext="n" display="inline"><mi>n</mi></math>, we have</p>
<table id="S0.Ex5" class="ltx_equation ltx_eqn_table">

<tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S0.Ex5.m1" class="ltx_Math" alttext="\Pr\left(-\delta&lt;\frac{1}{\sqrt{n}}\sum_{i=1}^{n}\frac{X_{i}-m}{\sqrt{v}}&lt;%
\delta\right)\approx 2\Phi(\delta)-1\,," display="block"><mrow><mrow><mrow><mi>Pr</mi><mo>‚Å°</mo><mrow><mo>(</mo><mrow><mrow><mo>-</mo><mi>Œ¥</mi></mrow><mo>&lt;</mo><mrow><mfrac><mn>1</mn><msqrt><mi>n</mi></msqrt></mfrac><mo>‚Å¢</mo><mrow><munderover><mo largeop="true" movablelimits="false" symmetric="true">‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mfrac><mrow><msub><mi>X</mi><mi>i</mi></msub><mo>-</mo><mi>m</mi></mrow><msqrt><mi>v</mi></msqrt></mfrac></mrow></mrow><mo>&lt;</mo><mi>Œ¥</mi></mrow><mo>)</mo></mrow></mrow><mo>‚âà</mo><mrow><mrow><mn>2</mn><mo>‚Å¢</mo><mi mathvariant="normal">Œ¶</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>Œ¥</mi><mo stretchy="false">)</mo></mrow></mrow><mo>-</mo><mpadded width="+1.7pt"><mn>1</mn></mpadded></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</table>
<p class="ltx_p">approximating the true distribution with the Gaussian cumulative
distribution function <math id="S0.SSx2.p1.m7" class="ltx_Math" alttext="\Phi" display="inline"><mi mathvariant="normal">Œ¶</mi></math>.
Setting <math id="S0.SSx2.p1.m8" class="ltx_Math" alttext="(1-\alpha)\times 100\%=2\Phi(\delta)-1" display="inline"><mrow><mrow><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>-</mo><mi>Œ±</mi></mrow><mo stretchy="false">)</mo></mrow><mo>√ó</mo><mrow><mn>100</mn><mo lspace="0pt" rspace="3.5pt">%</mo></mrow></mrow><mo>=</mo><mrow><mrow><mn>2</mn><mo>‚Å¢</mo><mi mathvariant="normal">Œ¶</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>Œ¥</mi><mo stretchy="false">)</mo></mrow></mrow><mo>-</mo><mn>1</mn></mrow></mrow></math> as the required
confidence level,
we have <math id="S0.SSx2.p1.m9" class="ltx_Math" alttext="\delta={\Phi}^{-1}(1-\alpha/2)" display="inline"><mrow><mi>Œ¥</mi><mo>=</mo><mrow><msup><mi mathvariant="normal">Œ¶</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><mi>Œ±</mi><mo>/</mo><mn>2</mn></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></math>.</p>
</div>
<div id="S0.SSx2.p2" class="ltx_para">
<p class="ltx_p">Thus, given an observation of the sample mean
from a run of the Monte Carlo simulation,
with <math id="S0.SSx2.p2.m1" class="ltx_Math" alttext="(1-\alpha)\times 100\%" display="inline"><mrow><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>-</mo><mi>Œ±</mi></mrow><mo stretchy="false">)</mo></mrow><mo>√ó</mo><mrow><mn>100</mn><mo lspace="0pt" rspace="3.5pt">%</mo></mrow></mrow></math> confidence,
the true mean <math id="S0.SSx2.p2.m2" class="ltx_Math" alttext="\mathbb{E}X" display="inline"><mrow><mi>ùîº</mi><mo>‚Å¢</mo><mi>X</mi></mrow></math> is approximately
within</p>
<table id="S0.Ex6" class="ltx_equation ltx_eqn_table">

<tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S0.Ex6.m1" class="ltx_Math" alttext="\pm\delta\sqrt{\frac{v}{n}}=\pm\sqrt{\frac{v}{n}}\,{\Phi}^{-1}(1-\alpha/2)" display="block"><mrow><mrow><mo>¬±</mo><mrow><mi>Œ¥</mi><mo>‚Å¢</mo><msqrt><mfrac><mi>v</mi><mi>n</mi></mfrac></msqrt></mrow></mrow><mo>=</mo><mrow><mo>¬±</mo><mrow><mpadded width="+1.7pt"><msqrt><mfrac><mi>v</mi><mi>n</mi></mfrac></msqrt></mpadded><mo>‚Å¢</mo><msup><mi mathvariant="normal">Œ¶</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><mi>Œ±</mi><mo>/</mo><mn>2</mn></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</table>
<p class="ltx_p">of the sample mean.</p>
</div>
<div id="S0.SSx2.p3" class="ltx_para">
<p class="ltx_p">Since the computed sample mean is random,
it is in general not possible to obtain actual error <em class="ltx_emph ltx_font_italic">bounds</em>,
in the usual sense of the word,
as with determistic algorithms.
Instead, the confidence interval size,
or the standard deviation of <math id="S0.SSx2.p3.m1" class="ltx_Math" alttext="(1/n)\sum_{i=1}^{n}X_{i}" display="inline"><mrow><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>/</mo><mi>n</mi></mrow><mo stretchy="false">)</mo></mrow><mo>‚Å¢</mo><mrow><msubsup><mo largeop="true" symmetric="true">‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msub><mi>X</mi><mi>i</mi></msub></mrow></mrow></math>,
is used as a measure of the error of Monte Carlo simulation;
this is sometimes called a <em class="ltx_emph ltx_font_italic">probabilistic error bound</em>.</p>
</div>
<div id="S0.SSx2.p4" class="ltx_para">
<p class="ltx_p">Observe that the probabilistic error bound of
the Monte Carlo simulation decreases as <math id="S0.SSx2.p4.m1" class="ltx_Math" alttext="1/\sqrt{n}" display="inline"><mrow><mn>1</mn><mo>/</mo><msqrt><mi>n</mi></msqrt></mrow></math>.</p>
</div>
</section>
<section id="S0.SSx3" class="ltx_subsection">
<h2 class="ltx_title ltx_title_subsection">Comparison with other methods</h2>

<div id="S0.SSx3.p1" class="ltx_para">
<dl id="I1" class="ltx_description">
<dt id="I1.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_description">Simplicity.</span></dt>
<dd class="ltx_item">
<div id="I1.ix1.p1" class="ltx_para">
<p class="ltx_p">The chief advantage of Monte Carlo simulation,
compared to the other numerical methods that can solve the same
problem, is that it is conceptually very simple.
It does not require specific knowledge of the form of the solution
or its analytic properties.
Monte Carlo is also relatively easy to implement on a computer.</p>
</div>
</dd>
<dt id="I1.ix2" class="ltx_item"><span class="ltx_tag ltx_tag_description">Slowness.</span></dt>
<dd class="ltx_item">
<div id="I1.ix2.p1" class="ltx_para">
<p class="ltx_p">The main disadvantage of Monte Carlo integration
is that it is slow.
Many samples may be
required ‚Äî on the order of thousands or even millions ‚Äî
to obtain acceptable precision in the answer.
In particular, since the probabilistic error bound
decreases as the reciprocal square root of the number of iterations,
to achieve one more decimal digit of precision
in the answer requires <math id="I1.ix2.p1.m1" class="ltx_Math" alttext="10^{2}=100" display="inline"><mrow><msup><mn>10</mn><mn>2</mn></msup><mo>=</mo><mn>100</mn></mrow></math> times more the
number of iterations.</p>
</div>
</dd>
</dl>
</div>
<div id="S0.SSx3.p2" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Other advantages of Monte Carlo</span>.</p>
<dl id="I2" class="ltx_description">
<dt id="I2.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_description">Independence of dimension.</span></dt>
<dd class="ltx_item">
<div id="I2.ix1.p1" class="ltx_para">
<p class="ltx_p">The amount of work to obtain the same amount of precision
is independent of the dimension <math id="I2.ix1.p1.m1" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math>
of the underlying random variables.</p>
</div>
<div id="I2.ix1.p2" class="ltx_para">
<p class="ltx_p">Thus Monte Carlo integration is practically the only method
to numerically compute high-dimensional integrals. Traditional
quadrature techniques generally require an amount of work
exponential in the number of dimensions <math id="I2.ix1.p2.m1" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math>,
since they require sampling a grid in <math id="I2.ix1.p2.m2" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math>-dimensional space.</p>
</div>
<div id="I2.ix1.p3" class="ltx_para">
<p class="ltx_p">On the other hand, Monte Carlo integration is generally
not competitive with quadrature for low-dimensional integration
(e.g. <math id="I2.ix1.p3.m1" class="ltx_Math" alttext="d=1" display="inline"><mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow></math> or <math id="I2.ix1.p3.m2" class="ltx_Math" alttext="d=2" display="inline"><mrow><mi>d</mi><mo>=</mo><mn>2</mn></mrow></math>).</p>
</div>
</dd>
<dt id="I2.ix2" class="ltx_item"><span class="ltx_tag ltx_tag_description">Unrestricted choice of functions.</span></dt>
<dd class="ltx_item">
<div id="I2.ix2.p1" class="ltx_para">
<p class="ltx_p">The functions to integrate with Monte Carlo
can be practically arbitrary.
No smoothness conditions or boundedness conditions are needed,
for example, providing the integral is finite.</p>
</div>
<div id="I2.ix2.p2" class="ltx_para">
<p class="ltx_p">(However, irregularities in the integrand
may impact the accuracy of the result.)</p>
</div>
</dd>
<dt id="I2.ix3" class="ltx_item"><span class="ltx_tag ltx_tag_description">Easily parallelizable.</span></dt>
<dd class="ltx_item">
<div id="I2.ix3.p1" class="ltx_para">
<p class="ltx_p">Many computer processors can be participating
in a Monte Carlo simulation simultaneously.
Each simulation is independent of another.</p>
</div>
</dd>
</dl>
</div>
<div id="S0.SSx3.p3" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Other disadvantages of Monte Carlo</span>.</p>
<dl id="I3" class="ltx_description">
<dt id="I3.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_description">Error may depend on distribution.</span></dt>
<dd class="ltx_item">
<div id="I3.ix1.p1" class="ltx_para">
<p class="ltx_p">The estimate of the expectation <math id="I3.ix1.p1.m1" class="ltx_Math" alttext="\mathbb{E}X" display="inline"><mrow><mi>ùîº</mi><mo>‚Å¢</mo><mi>X</mi></mrow></math> may be impacted
severely if the distribution of <math id="I3.ix1.p1.m2" class="ltx_Math" alttext="X" display="inline"><mi>X</mi></math> is heavily skewed
or has heavier-than-normal tails.
A non-random numerical method
may avoid these deficiencies,
or at least not be as severely impacted.</p>
</div>
</dd>
<dt id="I3.ix2" class="ltx_item"><span class="ltx_tag ltx_tag_description">Difficulty in estimating error.</span></dt>
<dd class="ltx_item">
<div id="I3.ix2.p1" class="ltx_para">
<p class="ltx_p">There are no hard bounds on the error of the computed result.
The probabilistic error bound, which is essentially based on the
variance, may not be a good measure
of the error for skewed distributions.</p>
</div>
</dd>
<dt id="I3.ix3" class="ltx_item"><span class="ltx_tag ltx_tag_description">Black-box approach.</span></dt>
<dd class="ltx_item">
<div id="I3.ix3.p1" class="ltx_para">
<p class="ltx_p">With some types of analytical approximation,
one can study the behavior of the solution
if the initial parameters are changed.
This generally is hard to do with
the black-box approach of Monte Carlo.</p>
</div>
</dd>
</dl>
</div>
</section>
<section id="S0.SSx4" class="ltx_subsection">
<h2 class="ltx_title ltx_title_subsection">Variance reduction</h2>

<div id="S0.SSx4.p1" class="ltx_para">
<p class="ltx_p">There are some variance reduction techniques
that can be used to reduce the error in the result
of a Monte Carlo simulation.
However, they generally cannot overcome the
slow <math id="S0.SSx4.p1.m1" class="ltx_Math" alttext="1/\sqrt{n}" display="inline"><mrow><mn>1</mn><mo>/</mo><msqrt><mi>n</mi></msqrt></mrow></math> decrease of the error inherent in Monte Carlo.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
      
<li id="bib.bib1" class="ltx_bibitem">
        <span class="ltx_bibtag ltx_role_refnum">1</span>
        
<span class="ltx_bibblock">
James E. Gentle. <em class="ltx_emph ltx_font_italic">Random Number Generation and Monte Carlo Methods</em>,
second edition. Springer, 2003.

</span>
      </li>
      
<li id="bib.bib2" class="ltx_bibitem">
        <span class="ltx_bibtag ltx_role_refnum">2</span>
        
<span class="ltx_bibblock">
‚Äú<span class="ltx_text ltx_font_typewriter">http://en.wikipedia.org/wiki/Monte_Carlo_method</span>Monte Carlo method‚Äù. Wikipedia, The Free Encyclopedia.
Accessed 27 June 2007.

</span>
      </li>
    
</ul>
</section>
<div id="p3" class="ltx_para ltx_align_right">
<table class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_t">Title</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Monte Carlo simulation</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Canonical name</td>
<td class="ltx_td ltx_align_left ltx_border_r">MonteCarloSimulation</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Date of creation</td>
<td class="ltx_td ltx_align_left ltx_border_r">2013-03-22 17:20:09</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Last modified on</td>
<td class="ltx_td ltx_align_left ltx_border_r">2013-03-22 17:20:09</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Owner</td>
<td class="ltx_td ltx_align_left ltx_border_r">stevecheng (10074)</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Last modified by</td>
<td class="ltx_td ltx_align_left ltx_border_r">stevecheng (10074)</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Numerical id</td>
<td class="ltx_td ltx_align_left ltx_border_r">5</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Author</td>
<td class="ltx_td ltx_align_left ltx_border_r">stevecheng (10074)</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Entry type</td>
<td class="ltx_td ltx_align_left ltx_border_r">Topic</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Classification</td>
<td class="ltx_td ltx_align_left ltx_border_r">msc 65C05</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Classification</td>
<td class="ltx_td ltx_align_left ltx_border_r">msc 62-00</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Classification</td>
<td class="ltx_td ltx_align_left ltx_border_r">msc 60-00</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Synonym</td>
<td class="ltx_td ltx_align_left ltx_border_r">Monte Carlo</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Synonym</td>
<td class="ltx_td ltx_align_left ltx_border_r">statistical sampling</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l">Synonym</td>
<td class="ltx_td ltx_align_left ltx_border_r">stochastic simulation</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l">Related topic</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r">AcceptanceRejectionMethod</td>
</tr>
</tbody>
</table>
</div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Feb 10 12:35:05 2018 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"></a>
</div></footer>
</div>
</body>
</html>
